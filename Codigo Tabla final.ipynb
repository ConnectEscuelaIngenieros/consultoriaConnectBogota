{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab51247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === RUTAS ===\n",
    "ruta_tabla_proyeccion = r\"20251003/ADP_DTM_FACT.Proyeccion.csv\"\n",
    "ruta_tabla_items = r\"20251003/ADP_DTM_DIM.Items.csv\"\n",
    "ruta_tabla_proyectos = r\"20251003/ADP_DTM_DIM.Proyecto.csv\"\n",
    "ruta_tabla_capitulos = r\"20251003/ADP_DTM_DIM.CapituloPresupuesto.csv\"\n",
    "ruta_tabla_insumos = r\"20251003/ADP_DTM_DIM.Insumo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6a7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARGA ===\n",
    "tabla_proyeccion = pd.read_csv(ruta_tabla_proyeccion)\n",
    "tabla_items = pd.read_csv(ruta_tabla_items, low_memory=False)\n",
    "tabla_proyectos = pd.read_csv(ruta_tabla_proyectos)\n",
    "tabla_capitulos = pd.read_csv(ruta_tabla_capitulos)\n",
    "tabla_insumos = pd.read_csv(ruta_tabla_insumos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44656a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Overlap antes de merge con insumos (deberÃ­a ser solo 'SkIdInsumo'): {'SkIdInsumo'}\n",
      "[DEBUG] OK. Forma final: (273450, 107)\n",
      "[DEBUG] OK. Forma final: (273450, 107)\n"
     ]
    }
   ],
   "source": [
    "tabla_base = tabla_proyeccion.copy()\n",
    "\n",
    "# Merges previos\n",
    "tabla_1 = pd.merge(tabla_base, tabla_proyectos, on=\"SkIdProyecto\", how=\"left\")\n",
    "tabla_2 = pd.merge(tabla_1, tabla_capitulos, on=\"SkIdCapitulo\", how=\"left\")\n",
    "\n",
    "# Asegura unicidad en Items\n",
    "tabla_items_unica = tabla_items.drop_duplicates(subset=[\"SkIdItems\"], keep=\"first\")\n",
    "tabla_3 = pd.merge(\n",
    "    tabla_2, tabla_items_unica,\n",
    "    on=\"SkIdItems\", how=\"left\",\n",
    "    suffixes=(\"\", \"_item\")   # control de sufijos para items\n",
    ")\n",
    "\n",
    "# ðŸ”§ FIX insumos: prefijar y garantizar clave Ãºnica\n",
    "tabla_insumos_unica = tabla_insumos.drop_duplicates(subset=[\"SkIdInsumo\"], keep=\"first\").copy()\n",
    "cols_no_clave_insumo = [c for c in tabla_insumos_unica.columns if c != \"SkIdInsumo\"]\n",
    "tabla_insumos_pref = tabla_insumos_unica.rename(\n",
    "    columns={c: f\"Insumo_{c}\" for c in cols_no_clave_insumo}\n",
    ")\n",
    "\n",
    "# (Opcional) Debug rÃ¡pido de posibles overlaps antes del merge final\n",
    "overlap_prev = set(tabla_3.columns).intersection(set(tabla_insumos_pref.columns))\n",
    "print(f\"[DEBUG] Overlap antes de merge con insumos (deberÃ­a ser solo 'SkIdInsumo'): {overlap_prev}\")\n",
    "\n",
    "# Merge final (sin sufijos porque ya prefijamos)\n",
    "tabla_4 = pd.merge(\n",
    "    tabla_3, tabla_insumos_pref,\n",
    "    on=\"SkIdInsumo\", how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "print(f\"[DEBUG] OK. Forma final: {tabla_4.shape}\")\n",
    "\n",
    "tabla_4.to_csv(\n",
    "    \"tabla_looker.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\",\"                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd0dfcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabla final exportada con 273450 filas y 22 columnas.\n"
     ]
    }
   ],
   "source": [
    "# === SELECCIÃ“N DE COLUMNAS ===\n",
    "columnas_finales = [\n",
    "    \"SkIdProyecto\", \"SkIdCapitulo\", \"SkIdItems\", \"SkIdInsumo\",\n",
    "    \"Nombre Proyecto\", \"Capitulo Descripcion\", \"Item Descripcion\", \"Insumo_Insumo Descripcion\", \"Insumo_Agrupacion Descripcion\",\n",
    "    \"SkIdFecha Real\", \"Cantidad\", \"Valor Unitario\", \"Valor Total\", \"Insumo_Valor Unitario\", \"Insumo_Valor Neto\", \"Insumo_Fecha Creacion\",\n",
    "    \"Cantidad Item\", \"Macroproyecto Descripcion\", \"Insumo_Fecha Modificacion\",\n",
    "    \"Fecha De Elaboracion\", \"Fecha De Inicio\", \"Fecha De FinalizaciÃ³n\", \"SkIdFecha\", \"Capitulo Numero\", \"Cantidad_Item\"\n",
    "]\n",
    "\n",
    "# Filtrar solo las columnas que existan realmente (por seguridad)\n",
    "columnas_existentes = [col for col in columnas_finales if col in tabla_4.columns]\n",
    "tabla_looker = tabla_4[columnas_existentes].copy()\n",
    "\n",
    "# === EXPORTAR ===\n",
    "tabla_looker.to_csv(\n",
    "    \"tabla_looker_final.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\",\")\n",
    "\n",
    "print(f\"âœ… Tabla final exportada con {len(tabla_looker)} filas y {len(tabla_looker.columns)} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ea80a",
   "metadata": {},
   "source": [
    "# CÃ³digo arreglado - Diana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7be1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Proceso completado. Archivo guardado en: 20251003/Tabla_Final_ARPRO_Completa.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === RUTAS ===\n",
    "ruta_tabla_proyeccion = r\"20251003/ADP_DTM_FACT.Proyeccion.csv\"\n",
    "ruta_tabla_items = r\"20251003/ADP_DTM_DIM.Items.csv\"\n",
    "ruta_tabla_proyectos = r\"20251003/ADP_DTM_DIM.Proyecto.csv\"\n",
    "ruta_tabla_capitulos = r\"20251003/ADP_DTM_DIM.CapituloPresupuesto.csv\"\n",
    "ruta_tabla_insumos = r\"20251003/ADP_DTM_DIM.Insumo.csv\"\n",
    "\n",
    "# === OPCIÃ“N: ruta de salida ===\n",
    "ruta_salida = r\"20251003/Tabla_Final_ARPRO_Completa.csv\"\n",
    "\n",
    "# === 1) Cargar y preparar Proyeccion ===\n",
    "proyeccion = pd.read_csv(ruta_tabla_proyeccion, low_memory=False)\n",
    "\n",
    "columnas_proyeccion = [\n",
    "    \"SkIdProyecto\",\n",
    "    \"SkIdCapitulo\",\n",
    "    \"SkIdItems\",\n",
    "    \"SkIdInsumo\",\n",
    "    \"SkIdFecha\",\n",
    "    \"SkIdFecha Real\",\n",
    "    \"Cantidad\",\n",
    "    \"Valor Unitario\",\n",
    "    \"Valor Total\"\n",
    "]\n",
    "\n",
    "missing = [c for c in columnas_proyeccion if c not in proyeccion.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas en Proyeccion: {missing}\")\n",
    "\n",
    "proyeccion_filtrada = proyeccion[columnas_proyeccion].copy()\n",
    "\n",
    "proyeccion_filtrada.rename(columns={\n",
    "    \"Cantidad\": \"Cantidad_Insumo\",\n",
    "    \"Valor Unitario\": \"Valor Unitario_Insumo\",\n",
    "    \"Valor Total\": \"Valor Total_Item\"\n",
    "}, inplace=True)\n",
    "\n",
    "# === 2) Cargar y preparar Proyecto ===\n",
    "proyecto = pd.read_csv(ruta_tabla_proyectos, low_memory=False)\n",
    "\n",
    "columnas_proyecto = [\n",
    "    \"SkIdProyecto\",\n",
    "    \"Codigo Proyecto\",\n",
    "    \"Nombre Proyecto\",\n",
    "    \"Clase Proyecto\",\n",
    "    \"Estado\",\n",
    "    \"MacroProyecto Descripcion\",\n",
    "    \"Fecha De Elaboracion\",\n",
    "    \"Fecha De Inicio\",\n",
    "    \"Fecha De Finalizacion\"\n",
    "]\n",
    "\n",
    "missing = [c for c in columnas_proyecto if c not in proyecto.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas en Proyecto: {missing}\")\n",
    "\n",
    "proyecto_filtrado = proyecto[columnas_proyecto].copy()\n",
    "\n",
    "proyecto_filtrado.rename(columns={\n",
    "    \"Estado\": \"Estado_Proyecto\",\n",
    "    \"MacroProyecto Descripcion\": \"MacroProyecto Descripcion_Proyecto\",\n",
    "    \"Fecha De Elaboracion\": \"MacroProyecto Fecha De Elaboracion_Proyecto\",\n",
    "    \"Fecha De Inicio\": \"MacroProyecto Fecha De Inicio_Proyecto\",\n",
    "    \"Fecha De Finalizacion\": \"MacroProyecto Fecha De Finalizacion_Proyecto\"\n",
    "}, inplace=True)\n",
    "\n",
    "merge_proyeccion_proyecto = pd.merge(\n",
    "    proyeccion_filtrada,\n",
    "    proyecto_filtrado,\n",
    "    on=\"SkIdProyecto\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "# === 3) Cargar Items ===\n",
    "items = pd.read_csv(ruta_tabla_items, low_memory=False)\n",
    "\n",
    "columnas_items = [\"SkIdItems\", \"Item Descripcion\"]\n",
    "missing = [c for c in columnas_items if c not in items.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas en Items: {missing}\")\n",
    "\n",
    "items_filtrado = items[columnas_items].copy()\n",
    "\n",
    "merge_items = pd.merge(\n",
    "    merge_proyeccion_proyecto,\n",
    "    items_filtrado,\n",
    "    on=\"SkIdItems\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "# === 4) Cargar Insumo ===\n",
    "insumo = pd.read_csv(ruta_tabla_insumos, low_memory=False)\n",
    "\n",
    "columnas_insumo = [\n",
    "    \"SkIdInsumo\",\n",
    "    \"Insumo Descripcion\",\n",
    "    \"Fecha Creacion\",\n",
    "    \"Fecha Modificacion\"\n",
    "]\n",
    "\n",
    "missing = [c for c in columnas_insumo if c not in insumo.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas en Insumo: {missing}\")\n",
    "\n",
    "insumo_filtrado = insumo[columnas_insumo].copy()\n",
    "\n",
    "insumo_filtrado.rename(columns={\n",
    "    \"Fecha Creacion\": \"Fecha Creacion_Insumo\",\n",
    "    \"Fecha Modificacion\": \"Fecha Modificacion_Insumo\"\n",
    "}, inplace=True)\n",
    "\n",
    "tabla_intermedia = pd.merge(\n",
    "    merge_items,\n",
    "    insumo_filtrado,\n",
    "    on=\"SkIdInsumo\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "# === 5) Cargar CapituloPresupuesto ===\n",
    "capitulo_presupuesto = pd.read_csv(ruta_tabla_capitulos, low_memory=False)\n",
    "\n",
    "columnas_capitulo = [\"Codigo Proyecto\", \"Capitulo Descripcion\"]\n",
    "missing = [c for c in columnas_capitulo if c not in capitulo_presupuesto.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas en CapituloPresupuesto: {missing}\")\n",
    "\n",
    "capitulo_filtrado = capitulo_presupuesto[columnas_capitulo].copy()\n",
    "\n",
    "if \"Codigo Proyecto\" not in tabla_intermedia.columns:\n",
    "    proyecto_cod = proyecto[[\"SkIdProyecto\", \"Codigo Proyecto\"]].drop_duplicates()\n",
    "    tabla_intermedia = pd.merge(\n",
    "        tabla_intermedia,\n",
    "        proyecto_cod,\n",
    "        on=\"SkIdProyecto\",\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\"\n",
    "    )\n",
    "\n",
    "tabla_final = pd.merge(\n",
    "    tabla_intermedia,\n",
    "    capitulo_filtrado,\n",
    "    on=\"Codigo Proyecto\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:m\"\n",
    ")\n",
    "\n",
    "# === 6) Rellenar valores faltantes segÃºn tus condiciones ===\n",
    "tabla_final[\"MacroProyecto Descripcion_Proyecto\"] = tabla_final[\"MacroProyecto Descripcion_Proyecto\"].fillna(\"No pertenece a un Macro Proyecto\")\n",
    "tabla_final[\"Insumo Descripcion\"] = tabla_final[\"Insumo Descripcion\"].fillna(\"Descripcion No Disponible\")\n",
    "tabla_final[\"Fecha Modificacion_Insumo\"] = tabla_final[\"Fecha Modificacion_Insumo\"].fillna(\"2009-12-31\")\n",
    "tabla_final[\"Fecha Creacion_Insumo\"] = tabla_final[\"Fecha Creacion_Insumo\"].fillna(\"2009-12-31\")\n",
    "\n",
    "# === 7) Guardar resultado a CSV ===\n",
    "tabla_final.to_csv(ruta_salida, index=False)\n",
    "\n",
    "print(\"âœ… Proceso completado. Archivo guardado en:\", ruta_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90ceedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(ruta_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "590adf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7488696, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe39f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Nombre Proyecto'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b869aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ExportaciÃ³n completada: 76 archivos creados en 'tablasProyect'.\n",
      "Ejemplos de archivos: ['URBAN_PLAZA', 'Parque_Engativa_-_Etapa_I', 'Edificio_Naia', 'PARQUE_ENGATIVA_ETAPA_II', 'Caminos_de_Sie_-_Urb_y_Zonas_Comunes_MZ_4']\n"
     ]
    }
   ],
   "source": [
    "# === EXPORTAR CSV POR PROYECTO ===\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Obtener el DataFrame fuente de forma robusta\n",
    "_df = None\n",
    "\n",
    "# a) Priorizar 'df' si ya existe (puede ser pandas o polars)\n",
    "try:\n",
    "    if 'df' in globals():\n",
    "        _candidate = df\n",
    "        # Si es Polars, convertir a pandas\n",
    "        if hasattr(_candidate, 'to_pandas'):\n",
    "            _candidate = _candidate.to_pandas()\n",
    "        if isinstance(_candidate, pd.DataFrame):\n",
    "            _df = _candidate.copy()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# b) Si no, usar 'tabla_final' si existe en memoria\n",
    "if _df is None:\n",
    "    try:\n",
    "        if 'tabla_final' in globals() and isinstance(tabla_final, pd.DataFrame):\n",
    "            _df = tabla_final.copy()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# c) Si no, intenta leer desde 'ruta_salida' si existe la variable y el archivo\n",
    "if _df is None:\n",
    "    try:\n",
    "        if 'ruta_salida' in globals() and isinstance(ruta_salida, str) and os.path.exists(ruta_salida):\n",
    "            _df = pd.read_csv(ruta_salida, low_memory=False)\n",
    "    except Exception:\n",
    "        _df = None\n",
    "\n",
    "# d) Si no, intenta con salidas previas de este notebook\n",
    "if _df is None:\n",
    "    for candidato in [\"tabla_looker_final.csv\", \"tabla_looker.csv\"]:\n",
    "        if os.path.exists(candidato):\n",
    "            _df = pd.read_csv(candidato, low_memory=False)\n",
    "            break\n",
    "\n",
    "if _df is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No se encontrÃ³ un DataFrame en memoria ('df' o 'tabla_final') ni archivos de salida ('ruta_salida', 'tabla_looker_final.csv', 'tabla_looker.csv'). \"\n",
    "        \"Ejecuta antes las celdas que generan la tabla final.\"\n",
    "    )\n",
    "\n",
    "# 2) Validar columna de proyecto\n",
    "col_proyecto = \"Nombre Proyecto\"\n",
    "if col_proyecto not in _df.columns:\n",
    "    # Ayuda: sugerir columnas relacionadas\n",
    "    candidatos = [c for c in _df.columns if \"proyecto\" in c.lower() or \"nombre\" in c.lower()]\n",
    "    raise KeyError(\n",
    "        f\"La columna '{col_proyecto}' no existe en los datos. Candidatos encontrados: {candidatos}\"\n",
    "    )\n",
    "\n",
    "# 3) Crear carpeta de salida\n",
    "carpeta_salida = \"tablasProyect\"\n",
    "os.makedirs(carpeta_salida, exist_ok=True)\n",
    "\n",
    "# 4) FunciÃ³n para sanear nombres de archivo en Windows\n",
    "invalid_re = re.compile(r\"[^A-Za-z0-9._-]+\")\n",
    "\n",
    "def slugify(nombre: str, max_len: int = 120) -> str:\n",
    "    if not isinstance(nombre, str):\n",
    "        nombre = str(nombre) if nombre is not None else \"\"\n",
    "    # Normalizar y quitar acentos\n",
    "    nombre = unicodedata.normalize(\"NFKD\", nombre).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    # Reemplazar separadores por guiones bajos\n",
    "    nombre = invalid_re.sub(\"_\", nombre).strip(\"._-\")\n",
    "    if not nombre:\n",
    "        nombre = \"SIN_NOMBRE\"\n",
    "    # Limitar longitud\n",
    "    return nombre[:max_len]\n",
    "\n",
    "# 5) Exportar un CSV por proyecto (evitando colisiones de nombre)\n",
    "proyectos = (\n",
    "    _df[col_proyecto]\n",
    "    .fillna(\"SIN_NOMBRE\")\n",
    "    .astype(str)\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "usados = {}\n",
    "exportados = 0\n",
    "\n",
    "for nombre in proyectos:\n",
    "    df_proj = _df[_df[col_proyecto].astype(str) == nombre]\n",
    "    base = slugify(nombre)\n",
    "    # Evitar colisiones si dos nombres diferentes se convierten al mismo slug\n",
    "    if base in usados:\n",
    "        usados[base] += 1\n",
    "        fname = f\"{base}_{usados[base]}.csv\"\n",
    "    else:\n",
    "        usados[base] = 1\n",
    "        fname = f\"{base}.csv\"\n",
    "\n",
    "    ruta_out = os.path.join(carpeta_salida, fname)\n",
    "    df_proj.to_csv(ruta_out, index=False, encoding=\"utf-8\")\n",
    "    exportados += 1\n",
    "\n",
    "print(f\"âœ… ExportaciÃ³n completada: {exportados} archivos creados en '{carpeta_salida}'.\")\n",
    "print(\"Ejemplos de archivos:\", list(usados.keys())[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
